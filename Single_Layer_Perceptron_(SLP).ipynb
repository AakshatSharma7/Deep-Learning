{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "91fc36f3-89d8-4483-ac07-6692754e6655",
      "metadata": {
        "id": "91fc36f3-89d8-4483-ac07-6692754e6655"
      },
      "source": [
        "###Single Layer Perceptron (SLP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "16773fa9-c81a-494b-9987-26eb78ebfe71",
      "metadata": {
        "id": "16773fa9-c81a-494b-9987-26eb78ebfe71"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e0fe9d-f74d-428b-af41-6dad994a26d2",
      "metadata": {
        "id": "c8e0fe9d-f74d-428b-af41-6dad994a26d2"
      },
      "source": [
        "### 1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fcef57c0-36b1-4ed2-ba96-1a60f21080fd",
      "metadata": {
        "id": "fcef57c0-36b1-4ed2-ba96-1a60f21080fd"
      },
      "outputs": [],
      "source": [
        "X = np.array(\n",
        "    [[7,1],\n",
        "    [5, -4],\n",
        "    [-3, -2],\n",
        "    [-2, 2]]\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4561402-b356-40f5-bfda-5a32ae2b0dc3",
      "metadata": {
        "id": "a4561402-b356-40f5-bfda-5a32ae2b0dc3",
        "outputId": "b939a2ee-e593-4c71-ad11-6bc442ded27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  1],\n",
              "       [ 5, -4],\n",
              "       [-3, -2],\n",
              "       [-2,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a720de2-6c68-4111-915b-db741cdea418",
      "metadata": {
        "id": "9a720de2-6c68-4111-915b-db741cdea418",
        "outputId": "0bbfe4ea-6bcb-4b3a-aaa7-30dd707a1b21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "Y = np.array([1,0,0,1])\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1c6e2c-4385-42c9-a7f7-a0b28772e252",
      "metadata": {
        "id": "de1c6e2c-4385-42c9-a7f7-a0b28772e252"
      },
      "source": [
        "### 2. Define the `activation function`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c123f34-06c8-48f5-a9c8-5303bfff785e",
      "metadata": {
        "id": "1c123f34-06c8-48f5-a9c8-5303bfff785e"
      },
      "source": [
        "- `unit step` activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b471299f-86e7-4b4b-a2e5-f985b377d62d",
      "metadata": {
        "id": "b471299f-86e7-4b4b-a2e5-f985b377d62d"
      },
      "outputs": [],
      "source": [
        "def step_af(z):\n",
        "    return 1 if z>=0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a612b7-2a68-4bec-8a54-a0c38fc8e350",
      "metadata": {
        "id": "a1a612b7-2a68-4bec-8a54-a0c38fc8e350"
      },
      "source": [
        "### 3. Define `Single Layer Perceptron Model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7426905b-d2ab-4c12-932b-98ea21b06f67",
      "metadata": {
        "id": "7426905b-d2ab-4c12-932b-98ea21b06f67"
      },
      "outputs": [],
      "source": [
        "### 3.a. Compute Cost\n",
        "def compute_cost(X,Y,W,b):\n",
        "    '''\n",
        "    X: Input Array\n",
        "    Y: Target (Y labels)\n",
        "    W: Weight Array\n",
        "    b: bias\n",
        "    '''\n",
        "    total_errors = 0 # how many misclassifications have happened\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        z = np.dot(W, X[i]) + b # weighted sum of inputs + bias --> one row at a time\n",
        "        y_pred = step_af(z) # predicted value using unit step activation function\n",
        "\n",
        "        if y_pred != Y[i]: # comparing predicted Y against actual Y\n",
        "            total_errors += 1 #counting the instances of error\n",
        "    return total_errors\n",
        "\n",
        "#### 3.b. Let us create the SLP train\n",
        "\n",
        "def slp_train(X, Y, W, b, alpha, epochs):\n",
        "    ### Create the couple of empty lists to track historical updates\n",
        "    errors_per_epoch = []\n",
        "    accuracy_per_epoch = []\n",
        "\n",
        "    ### Suppress scientific notation and control decimals\n",
        "    np.set_printoptions(precision = 2, suppress = True)\n",
        "\n",
        "    for epoch in range(epochs): # outer for loop\n",
        "        print(f\"\\nEpoch# {epoch + 1}\")\n",
        "\n",
        "        total_errors = 0 # instances of mis-classification\n",
        "        correct = 0 #instances of correct classification\n",
        "\n",
        "        for i in range(len(X)): # inner for loop\n",
        "            x = X[i] # picking a row - one at a time\n",
        "            y = Y[i] # picking the target label for that specific row -- actual Y\n",
        "            z = np.dot(W,x) + b # weighted sum of inputs + bias\n",
        "            y_pred = step_af(z) # predicted Y\n",
        "            error = y_pred - y # calculate error\n",
        "\n",
        "            if error != 0:\n",
        "                ### Since there is an error, need to update weights & biases\n",
        "                W = W - (alpha * (error * x))\n",
        "                b = b - (alpha * error)\n",
        "                total_errors += 1\n",
        "            else:\n",
        "                correct += 1\n",
        "            cost = compute_cost(X, Y, W, b)\n",
        "            # Well-formatted log output\n",
        "            print(f\"{'Input:':<10} {x}  \"\n",
        "                  f\"{'Prediction:':<12} {y_pred}  \"\n",
        "                  f\"{'Actual:':<8} {y}  \"\n",
        "                  f\"{'Error:':<7} {error}  \"\n",
        "                  f\"{'Weights:':<9} {W}  \"\n",
        "                  f\"{'Bias:':<6} {b:.3f}  \"\n",
        "                  f\"{'Cost:':<6} {cost}\")\n",
        "\n",
        "        errors_per_epoch.append(total_errors) #appending the historical errors\n",
        "        accuracy_per_epoch.append(correct/len(X)) #appending the avg. correct instances\n",
        "\n",
        "    return W, b, errors_per_epoch, accuracy_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "584efcf6-cfb7-4eb8-a297-1916ce6e610f",
      "metadata": {
        "id": "584efcf6-cfb7-4eb8-a297-1916ce6e610f",
        "outputId": "ea3b77b0-044d-4def-a587-0844933d6c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d92124d0-8c81-406b-9706-a0b429f28591",
      "metadata": {
        "id": "d92124d0-8c81-406b-9706-a0b429f28591"
      },
      "outputs": [],
      "source": [
        "W = np.array([0.5, -0.5]) #weights are as many as number of X features--> number of input variables\n",
        "b = 0.1\n",
        "alpha = 0.1\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbea10cb-105b-4ded-9ff4-ed5f40b2c3b2",
      "metadata": {
        "id": "cbea10cb-105b-4ded-9ff4-ed5f40b2c3b2"
      },
      "source": [
        "#### `Let us try running with `SLP` with `initial weights and biases` set by modeler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8bdad4ec-d420-4c22-8ebd-4f2279431034",
      "metadata": {
        "id": "8bdad4ec-d420-4c22-8ebd-4f2279431034"
      },
      "outputs": [],
      "source": [
        "W = np.array([0.5, -0.5]) #weights are as many as number of X features--> number of input variables\n",
        "b = 0.1\n",
        "alpha = 0.1 #standard learning rate\n",
        "epochs = 10 #number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3442e024-e8ce-418c-805f-6fb7c97159b7",
      "metadata": {
        "id": "3442e024-e8ce-418c-805f-6fb7c97159b7",
        "outputId": "34664c85-2b0a-402c-ec09-81104ce70f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch# 1\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [ 0.5 -0.5]  Bias:  0.100  Cost:  2\n",
            "Input:     [ 5 -4]  Prediction:  1  Actual:  0  Error:  1  Weights:  [ 0.  -0.1]  Bias:  0.000  Cost:  4\n",
            "Input:     [-3 -2]  Prediction:  1  Actual:  0  Error:  1  Weights:  [0.3 0.1]  Bias:  -0.100  Cost:  2\n",
            "Input:     [-2  2]  Prediction:  0  Actual:  1  Error:  -1  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 2\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 3\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 4\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 5\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 6\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 7\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 8\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 9\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "\n",
            "Epoch# 10\n",
            "Input:     [7 1]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [ 5 -4]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-3 -2]  Prediction:  0  Actual:  0  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n",
            "Input:     [-2  2]  Prediction:  1  Actual:  1  Error:  0  Weights:  [0.1 0.3]  Bias:  0.000  Cost:  0\n"
          ]
        }
      ],
      "source": [
        "final_W, final_b, errors, accuracy = slp_train(X, Y, W, b, alpha, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcaf1ad4-ae6c-43a6-a4a3-ad61ce34b9e7",
      "metadata": {
        "id": "dcaf1ad4-ae6c-43a6-a4a3-ad61ce34b9e7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}